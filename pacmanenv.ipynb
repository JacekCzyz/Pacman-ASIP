{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "from run import GameController\n",
    "from constants import *\n",
    "from pacman import Pacman\n",
    "from ghost import Ghosts\n",
    "from nodes import NodeGroup\n",
    "from pellets import PelletGroup\n",
    "from fruits import Fruits\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "\n",
    "class PacmanEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "class PacmanEnv(gym.Env):\n",
    "    def __init__(self, render_mode=False):\n",
    "        super(PacmanEnv, self).__init__()\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        if not render_mode:\n",
    "            os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "        else:\n",
    "            os.environ.pop(\"SDL_VIDEODRIVER\", None)\n",
    "\n",
    "        pygame.quit() \n",
    "        pygame.init()\n",
    "\n",
    "        self.game = GameController(render_mode=render_mode)\n",
    "\n",
    "        self.action_space = spaces.Discrete(5, start=-2)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255, shape=(SCREENHEIGHT, SCREENWIDTH, 3), dtype=np.uint8\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.startGame(3)\n",
    "        state = self.get_observation()\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = int(action)\n",
    "        action = np.clip(action, 0, 4)\n",
    "    \n",
    "        action = action - 2\n",
    "        if self.game.pacman.validDirection(action):\n",
    "            self.game.pacman.direction = action \n",
    "\n",
    "        pelletBefore = self.game.pellets.numEaten \n",
    "        lifesBefore = self.game.pacman.life_amount   \n",
    "        self.game.update()\n",
    "\n",
    "        if self.game.pacman.target is not None and self.game.pacman.overshotTarget():\n",
    "            self.game.pacman.node = self.game.pacman.target\n",
    "            self.game.pacman.setPosition()\n",
    "\n",
    "        self.game.update() \n",
    "\n",
    "        state = self.get_observation() \n",
    "\n",
    "        reward = 0\n",
    "\n",
    "        pellet = self.game.pellets.numEaten - pelletBefore\n",
    "        if pellet == 1:\n",
    "            reward += 20\n",
    "\n",
    "        fruit = None\n",
    "        if self.game.fruits is not None:\n",
    "            fruit = self.game.pacman.eatFruits(self.game.fruits)\n",
    "            if fruit:\n",
    "                reward += 20\n",
    "\n",
    "        lifes = self.game.pacman.life_amount - lifesBefore\n",
    "        if lifes == -1:\n",
    "            reward -= 50\n",
    "\n",
    "\n",
    "        if pellet == 0 and fruit is None:\n",
    "            reward -= 2\n",
    "\n",
    "        done = self.check_game_over()\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return state, reward, done, info\n",
    "    \n",
    "    def render(self, mode=\"human\"):\n",
    "        if self.render_mode and mode == \"human\":\n",
    "            self.game.render()\n",
    "\n",
    "    def get_observation(self):\n",
    "        return pygame.surfarray.array3d(self.game.screen)\n",
    "\n",
    "    def _init_pygame(self):\n",
    "        if not pygame.get_init():\n",
    "            pygame.init()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def check_game_over(self):\n",
    "        return self.game.pacman.life_amount == 0\n",
    "    \n",
    "    def change_resolution(self, width, height):\n",
    "        global SCREENWIDTH, SCREENHEIGHT\n",
    "\n",
    "        constants_path = os.path.join(os.path.dirname(__file__), \"constants.py\")\n",
    "        with open(constants_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with open(constants_path, \"w\") as file:\n",
    "            for line in lines:\n",
    "                if line.startswith(\"SCREENWIDTH\"):\n",
    "                    file.write(f\"SCREENWIDTH = {width}\\n\")\n",
    "                elif line.startswith(\"SCREENHEIGHT\"):\n",
    "                    file.write(f\"SCREENHEIGHT = {height}\\n\")\n",
    "                else:\n",
    "                    file.write(line)\n",
    "\n",
    "        SCREENWIDTH, SCREENHEIGHT = width, height\n",
    "        \n",
    "        self.game.screen = pygame.display.set_mode((SCREENWIDTH, SCREENHEIGHT))\n",
    "        self.game.width, self.game.height = SCREENWIDTH, SCREENHEIGHT\n",
    "\n",
    "    def get_observation(self):\n",
    "        observation = pygame.surfarray.array3d(self.game.screen)\n",
    "        return np.transpose(observation, (1, 0, 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Training the model...\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 193      |\n",
      "|    ep_rew_mean      | 600      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 662      |\n",
      "|    total_timesteps  | 772      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.28     |\n",
      "|    n_updates        | 167      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 161      |\n",
      "|    ep_rew_mean      | 834      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 1168     |\n",
      "|    total_timesteps  | 1285     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.71     |\n",
      "|    n_updates        | 296      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 165      |\n",
      "|    ep_rew_mean      | 926      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 1850     |\n",
      "|    total_timesteps  | 1983     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.71     |\n",
      "|    n_updates        | 470      |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = PacmanEnv(render_mode=False)\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1, buffer_size=1000)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "model.learn(total_timesteps=2000)\n",
    "model.save(\"pacman_dqn_model\")\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to testing mode...\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "-1978\n"
     ]
    }
   ],
   "source": [
    "print(\"Switching to testing mode...\")\n",
    "env = PacmanEnv(render_mode=True)\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1, buffer_size=1000)\n",
    "\n",
    "model.load(\"pacman_dqn_model.zip\")\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "rewards = []\n",
    "durations = []\n",
    "episodes = 15\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        steps += 1\n",
    "\n",
    "    rewards.append(episode_reward)\n",
    "    durations.append(steps)\n",
    "\n",
    "file = open(\"tests.txt\")\n",
    "file.write(\"DQN model for {episodes} episodes\")    \n",
    "for i in range(rewards.count()):\n",
    "    file.write(\"episode {i}:\", \"reward \",rewards[i], \" duration: \", durations[i])    \n",
    "    \n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PacmanEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_vec_env\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the Pacman environment in training mode\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mPacmanEnv\u001b[49m(render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Use training mode (no rendering)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize PPO model with CnnPolicy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCnnPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, ent_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PacmanEnv' is not defined"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "env = PacmanEnv(render_mode=False)\n",
    "    \n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, n_steps=256, batch_size=64, ent_coef=0.01)\n",
    "\n",
    "print(\"Training the PPO model...\")\n",
    "model.learn(total_timesteps=100)\n",
    "model.save(\"pacman_ppo_model\")\n",
    "env.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Switching to testing mode...\")\n",
    "env = PacmanEnv(render_mode=True)  # New environment with rendering enabled\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, n_steps=256, batch_size=64, ent_coef=0.01)\n",
    "\n",
    "model.load(\"pacman_ppo_model.zip\")\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "rewards = []\n",
    "durations = []\n",
    "episodes = 15\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        steps += 1\n",
    "\n",
    "    rewards.append(episode_reward)\n",
    "    durations.append(steps)\n",
    "\n",
    "file = open(\"tests.txt\")\n",
    "file.write(\"ppo model for {episodes} episodes\")    \n",
    "for i in range(rewards.count()):\n",
    "    file.write(\"episode {i}:\", \"reward \",rewards[i], \" duration: \", durations[i])    \n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
