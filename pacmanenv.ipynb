{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "from run import GameController\n",
    "from constants import *\n",
    "from pacman import Pacman\n",
    "from ghost import Ghosts\n",
    "from nodes import NodeGroup\n",
    "from pellets import PelletGroup\n",
    "from fruits import Fruits\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "import time\n",
    "class PacmanEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "class PacmanEnv(gym.Env):\n",
    "    def __init__(self, render_mode=False):\n",
    "        super(PacmanEnv, self).__init__()\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        if not render_mode:\n",
    "            os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "        else:\n",
    "            os.environ.pop(\"SDL_VIDEODRIVER\", None)\n",
    "\n",
    "        pygame.quit() \n",
    "        pygame.init()\n",
    "\n",
    "        self.game = GameController(render_mode=render_mode)\n",
    "\n",
    "        self.action_space = spaces.Discrete(5, start=-2)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255, shape=(SCREENHEIGHT, SCREENWIDTH, 3), dtype=np.uint8\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.startGame(3)\n",
    "        state = self.get_observation()\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = int(action)\n",
    "        action = np.clip(action, 0, 4)\n",
    "    \n",
    "        action = action - 2\n",
    "        if self.game.pacman.validDirection(action):\n",
    "            self.game.pacman.direction = action \n",
    "\n",
    "        pelletBefore = self.game.pellets.numEaten \n",
    "        lifesBefore = self.game.pacman.life_amount   \n",
    "        self.game.update()\n",
    "\n",
    "        if self.game.pacman.target is not None and self.game.pacman.overshotTarget():\n",
    "            self.game.pacman.node = self.game.pacman.target\n",
    "            self.game.pacman.setPosition()\n",
    "\n",
    "        self.game.update() \n",
    "\n",
    "        state = self.get_observation() \n",
    "\n",
    "        reward = 0\n",
    "\n",
    "        pellet = self.game.pellets.numEaten - pelletBefore\n",
    "        if pellet == 1:\n",
    "            reward += 20\n",
    "\n",
    "        fruit = None\n",
    "        if self.game.fruits is not None:\n",
    "            fruit = self.game.pacman.eatFruits(self.game.fruits)\n",
    "            if fruit:\n",
    "                reward += 20\n",
    "\n",
    "        lifes = self.game.pacman.life_amount - lifesBefore\n",
    "        if lifes == -1:\n",
    "            reward -= 50\n",
    "\n",
    "\n",
    "        if pellet == 0 and fruit is None:\n",
    "            reward -= 2\n",
    "\n",
    "        done = self.check_game_over()\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return state, reward, done, info\n",
    "    \n",
    "    def render(self, mode=\"human\"):\n",
    "        if self.render_mode and mode == \"human\":\n",
    "            self.game.render()\n",
    "\n",
    "    def get_observation(self):\n",
    "        return pygame.surfarray.array3d(self.game.screen)\n",
    "\n",
    "    def _init_pygame(self):\n",
    "        if not pygame.get_init():\n",
    "            pygame.init()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def check_game_over(self):\n",
    "        return self.game.pacman.life_amount == 0\n",
    "    \n",
    "    def change_resolution(self, width, height):\n",
    "        global SCREENWIDTH, SCREENHEIGHT\n",
    "\n",
    "        constants_path = os.path.join(os.path.dirname(__file__), \"constants.py\")\n",
    "        with open(constants_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with open(constants_path, \"w\") as file:\n",
    "            for line in lines:\n",
    "                if line.startswith(\"SCREENWIDTH\"):\n",
    "                    file.write(f\"SCREENWIDTH = {width}\\n\")\n",
    "                elif line.startswith(\"SCREENHEIGHT\"):\n",
    "                    file.write(f\"SCREENHEIGHT = {height}\\n\")\n",
    "                else:\n",
    "                    file.write(line)\n",
    "\n",
    "        SCREENWIDTH, SCREENHEIGHT = width, height\n",
    "        \n",
    "        self.game.screen = pygame.display.set_mode((SCREENWIDTH, SCREENHEIGHT))\n",
    "        self.game.width, self.game.height = SCREENWIDTH, SCREENHEIGHT\n",
    "\n",
    "    def get_observation(self):\n",
    "        observation = pygame.surfarray.array3d(self.game.screen)\n",
    "        return np.transpose(observation, (1, 0, 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m PacmanEnv(render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCnnPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:104\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     78\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[DQNPolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    103\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No action noise\u001b[39;49;00m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_initial_eps \u001b[38;5;241m=\u001b[39m exploration_initial_eps\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_final_eps \u001b[38;5;241m=\u001b[39m exploration_final_eps\n",
      "File \u001b[1;32mc:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:110\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     82\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[BasePolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     supported_action_spaces: Optional[Tuple[Type[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ):\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupport_multi_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size \u001b[38;5;241m=\u001b[39m buffer_size\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[1;32mc:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:169\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     env \u001b[38;5;241m=\u001b[39m maybe_make_env(env, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m--> 169\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\n",
      "File \u001b[1;32mc:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:216\u001b[0m, in \u001b[0;36mBaseAlgorithm._wrap_env\u001b[1;34m(env, verbose, monitor_wrapper)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" \"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mWrap environment with the appropriate wrappers if needed.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03mFor instance, to have a vectorized environment\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m:return: The wrapped environment.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, VecEnv):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# Patch to support gym 0.21/0.26 and gymnasium\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43m_patch_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_wrapped(env, Monitor) \u001b[38;5;129;01mand\u001b[39;00m monitor_wrapper:\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:40\u001b[0m, in \u001b[0;36m_patch_env\u001b[1;34m(env)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment is of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(env)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, not a Gymnasium \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment. In this case, we expect OpenAI Gym to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstalled and the environment to be an OpenAI Gym environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m     )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshimmy\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing shimmy installation. You provided an OpenAI Gym environment. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStable-Baselines3 (SB3) has transitioned to using Gymnasium internally. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use OpenAI Gym environments with SB3, you need to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall shimmy (`pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshimmy>=2.0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shimmy\\__init__.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshimmy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdm_lab_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DmLabCompatibilityV0\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshimmy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_gym_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GymV21CompatibilityV0, GymV26CompatibilityV0\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshimmy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_gymnasium_envs\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# this registers the environments on `import shimmy`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shimmy\\openai_gym_compatibility.py:23\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     Box,\n\u001b[0;32m     14\u001b[0m     Dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     Tuple,\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep_api_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     convert_to_terminated_truncated_step_api,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1080\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1504\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1476\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1612\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = PacmanEnv(render_mode=False)\n",
    "model = DQN(\"CnnPolicy\", env, verbose=1, buffer_size=1000)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "for i in range(15):\n",
    "    model.learn(total_timesteps=1500)\n",
    "    env.reset\n",
    "    print(i)\n",
    "\n",
    "model.save(\"pacman_10x5000dqn_model\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to testing mode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n",
      "c:\\Users\\jacek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting episode0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "quitting\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "quitting\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(state)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(action)\n\u001b[1;32m---> 33\u001b[0m state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     35\u001b[0m steps_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m steptime\n",
      "Cell \u001b[1;32mIn[2], line 55\u001b[0m, in \u001b[0;36mPacmanEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     53\u001b[0m pelletBefore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mpellets\u001b[38;5;241m.\u001b[39mnumEaten \n\u001b[0;32m     54\u001b[0m lifesBefore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mpacman\u001b[38;5;241m.\u001b[39mlife_amount   \n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mpacman\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mpacman\u001b[38;5;241m.\u001b[39movershotTarget():\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mpacman\u001b[38;5;241m.\u001b[39mnode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mpacman\u001b[38;5;241m.\u001b[39mtarget\n",
      "File \u001b[1;32mc:\\Users\\jacek\\source\\repos\\Pacman\\run.py:64\u001b[0m, in \u001b[0;36mGameController.update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckCollisionEvents()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckEvents()\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jacek\\source\\repos\\Pacman\\run.py:136\u001b[0m, in \u001b[0;36mGameController.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshowScore(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSDL_VIDEODRIVER\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Switching to testing mode...\")\n",
    "env = PacmanEnv(render_mode=False) #rendering wyłączony, True w celu włączenia - wyświetla się okno pygame z przebiegiem gry\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "#model = DQN(\"MlpPolicy\", env, verbose=1, buffer_size=1000)\n",
    "\n",
    "model = DQN.load(\"pacman_10x5000dqn_model.zip\")\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "rewards = []\n",
    "durations = []\n",
    "times=[]\n",
    "episodes = 20\n",
    "max_episode_time = 5 * 60\n",
    "scores=[]\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "    steps_time = 0\n",
    "    done = False\n",
    "    episode_start_time = time.time()\n",
    "    score=0\n",
    "    print(\"starting episode\" + str(episode))\n",
    "    while not done:\n",
    "        if time.time() - episode_start_time >= max_episode_time:\n",
    "            print(f\"Episode {episode} exceeded 10 minutes, stopping early.\")\n",
    "            break\n",
    "        steptime = time.time()\n",
    "        action, _ = model.predict(state)\n",
    "        # print(action)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        steps_time += time.time() - steptime\n",
    "        steps += 1\n",
    "        env.render()\n",
    "    scores.append(env.game.score)\n",
    "    times.append(steps_time/steps)\n",
    "    rewards.append(episode_reward)\n",
    "    durations.append(steps)\n",
    "env.close()\n",
    "mean_score = 0\n",
    "for score in scores:\n",
    "    mean_score+=score\n",
    "mean_score = mean_score/episodes\n",
    "file = open(\"tests.txt\", \"a\")\n",
    "file.write(\"DQN model for \" + str(episodes) + \" episodes\\n\")    \n",
    "file.write(\"score: \" + str(mean_score))    \n",
    "\n",
    "for i in range(len(rewards)):\n",
    "    file.write(\"episode\" + str(i)+ \" :\" + \"reward \" + str(rewards[i]) + \" duration: \" + str(durations[i]) + \" mean step time: \" + str(times[i])+\"\\n\")     \n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PacmanEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_vec_env\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the Pacman environment in training mode\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mPacmanEnv\u001b[49m(render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Use training mode (no rendering)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize PPO model with CnnPolicy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCnnPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, ent_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PacmanEnv' is not defined"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "env = PacmanEnv(render_mode=False)\n",
    "    \n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, n_steps=256, batch_size=64, ent_coef=0.01)\n",
    "\n",
    "print(\"Training the PPO model...\")\n",
    "for i in range(10):\n",
    "    model.learn(total_timesteps=5000)\n",
    "    env.reset\n",
    "    print(i)\n",
    "\n",
    "model.save(\"pacman_10x5000ppo_model\")\n",
    "env.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to testing mode...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PacmanEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSwitching to testing mode...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mPacmanEnv\u001b[49m(render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      4\u001b[0m rewardMain \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PacmanEnv' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Switching to testing mode...\")\n",
    "env = PacmanEnv(render_mode=False) #rendering wyłączony, True w celu włączenia - wyświetla się okno pygame z przebiegiem gry\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "# model = DQN(\"MlpPolicy\", env, verbose=1, buffer_size=1000)\n",
    "\n",
    "model = PPO.load(\"pacman_10x5000ppo_model.zip\")\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "rewards = []\n",
    "durations = []\n",
    "times=[]\n",
    "episodes = 20\n",
    "max_episode_time = 5 * 60\n",
    "scores=[]\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "    steps_time = 0\n",
    "    done = False\n",
    "    episode_start_time = time.time()\n",
    "    score=0\n",
    "    print(\"starting episode\" + str(episode))\n",
    "    while not done:\n",
    "        if time.time() - episode_start_time >= max_episode_time:\n",
    "            print(f\"Episode {episode} exceeded 10 minutes, stopping early.\")\n",
    "            break\n",
    "        steptime = time.time()\n",
    "        action, _ = model.predict(state)\n",
    "        print(action)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        steps_time += time.time() - steptime\n",
    "        steps += 1\n",
    "        env.render()\n",
    "    scores.append(env.game.score)\n",
    "    times.append(steps_time/steps)\n",
    "    rewards.append(episode_reward)\n",
    "    durations.append(steps)\n",
    "env.close()\n",
    "mean_score = 0\n",
    "for score in scores:\n",
    "    mean_score+=score\n",
    "mean_score = mean_score/episodes\n",
    "file = open(\"ppo_tests.txt\", \"a\")\n",
    "file.write(\"PPO model for \" + str(episodes) + \" episodes\\n\")    \n",
    "file.write(\"score: \" + str(mean_score))    \n",
    "\n",
    "for i in range(len(rewards)):\n",
    "    file.write(\"episode\" + str(i)+ \" :\" + \"reward \" + str(rewards[i]) + \" duration: \" + str(durations[i]) + \" mean step time: \" + str(times[i])+\"\\n\")     \n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trained PPO model:\")\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(state)\n",
    "\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    env.render()\n",
    "    rewardMain += reward\n",
    "\n",
    "    if done:\n",
    "        print(\"Game Over\")\n",
    "        break\n",
    "\n",
    "print(f\"Total reward during testing: {rewardMain}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_net.q_net.0.weight: wartości =\n",
      "[[ 2.3925076e-04 -6.5672200e-04  5.3224515e-04 ...  5.3460681e-04\n",
      "   3.4163723e-04 -7.2052394e-04]\n",
      " [ 5.9212238e-04 -4.4889134e-04  7.8002218e-04 ... -3.8859915e-04\n",
      "  -6.8005506e-04 -1.2634526e-04]\n",
      " [ 3.0158254e-04 -7.8318124e-05  4.6163899e-05 ... -5.7490659e-04\n",
      "  -6.3181494e-04 -8.2540227e-04]\n",
      " ...\n",
      " [-7.7338779e-04  3.3001532e-04 -5.0240004e-04 ...  8.0900890e-04\n",
      "   6.5231504e-04  7.0917537e-04]\n",
      " [ 6.9504359e-04 -5.4917444e-04  5.4113590e-04 ...  1.4747500e-04\n",
      "   1.0414750e-04 -6.4103416e-04]\n",
      " [-3.1208736e-04 -3.3204953e-04 -9.6093914e-05 ...  3.7679175e-04\n",
      "   1.5308202e-04  4.0787220e-04]]\n",
      "q_net.q_net.0.bias: wartości =\n",
      "[-1.1789298e-03 -6.2681836e-05 -4.2216206e-04 -7.8597368e-04\n",
      "  4.5443727e-03 -7.6337933e-04  5.7958992e-04 -2.5106332e-04\n",
      "  6.7077945e-03 -8.1022724e-04  2.7512228e-03  7.0024695e-04\n",
      " -1.2908038e-03 -4.5241287e-04 -1.5699057e-03 -1.9009312e-04\n",
      " -5.6728095e-05  1.2117593e-04 -3.0146159e-05  4.4372808e-03\n",
      " -8.0119423e-04 -4.0292513e-04 -7.5588777e-04  5.7186042e-03\n",
      " -5.3931883e-04 -3.9345908e-04 -6.9844257e-04 -4.9554277e-04\n",
      " -7.4380462e-04 -1.6364947e-04  5.2252170e-03 -6.9440267e-04\n",
      " -5.0244341e-04 -1.1874967e-03  2.9366419e-03  7.2482333e-04\n",
      "  1.3077428e-03 -4.4551658e-04 -2.3833276e-03  5.4836920e-03\n",
      " -5.4286799e-04 -4.2036193e-04  8.8378903e-04 -6.0028624e-04\n",
      "  6.0584764e-03 -1.0116359e-03  4.8825890e-03  1.1716617e-03\n",
      " -8.0896134e-05 -1.4180418e-03  1.4103762e-03  5.0440216e-03\n",
      " -6.4969639e-04 -5.1396291e-05 -1.1329775e-03  1.2523439e-03\n",
      " -1.0288768e-05 -9.6440915e-04 -1.3163767e-03 -1.4507649e-03\n",
      " -4.5566112e-04 -5.0748611e-04 -7.3393097e-04 -3.9002139e-04]\n",
      "q_net.q_net.2.weight: wartości =\n",
      "[[-0.10306998 -0.04740344 -0.04613036 ... -0.12322089 -0.0296732\n",
      "  -0.03088734]\n",
      " [ 0.02961031  0.02182902  0.05546771 ... -0.12281612  0.01522672\n",
      "  -0.12456033]\n",
      " [-0.11510165 -0.10880047 -0.11405376 ...  0.06042151  0.01270445\n",
      "   0.03763252]\n",
      " ...\n",
      " [-0.07725271 -0.09243435 -0.10605598 ... -0.11237203 -0.07401535\n",
      "  -0.0013534 ]\n",
      " [-0.058766   -0.09200688  0.01365319 ...  0.0551217  -0.06085988\n",
      "   0.08738093]\n",
      " [ 0.06602754  0.03505161 -0.06436748 ... -0.08774966  0.07878042\n",
      "  -0.00941203]]\n",
      "q_net.q_net.2.bias: wartości =\n",
      "[-0.11907395 -0.09947535  0.00084285 -0.12160436 -0.06967366 -0.01284874\n",
      " -0.05625974 -0.07340997 -0.03108834 -0.1155099   0.05889735  0.12092204\n",
      " -0.11863756 -0.03545842  0.05567651 -0.0656056  -0.08704472 -0.06298754\n",
      "  0.04860168 -0.06694451 -0.06560093  0.01748656 -0.10362199 -0.12838262\n",
      " -0.0939144  -0.11193378  0.0061839   0.01686882 -0.12056156  0.06359376\n",
      " -0.02093779 -0.11919798 -0.10072511 -0.08881746 -0.1262908  -0.10048323\n",
      "  0.10057727 -0.0611189   0.04093122 -0.10811616  0.02131113  0.01597142\n",
      " -0.08551478 -0.04891859  0.03077989 -0.01711522  0.02403663  0.04102797\n",
      " -0.05097852 -0.07462391 -0.04489069  0.10967866 -0.1222527  -0.02364988\n",
      "  0.05883508 -0.08379245 -0.02366786 -0.08930821  0.09144378  0.0918896\n",
      "  0.00692388  0.08050785 -0.11167869  0.00158239]\n",
      "q_net.q_net.4.weight: wartości =\n",
      "[[ 0.09309925 -0.04631676 -0.03375402  0.09081764  0.10155195 -0.05086781\n",
      "  -0.04929595  0.04271331  0.05608333  0.12533718  0.02642475  0.08708175\n",
      "  -0.0749092   0.07150223 -0.01468704  0.12011388  0.04359646  0.03170392\n",
      "  -0.05570926 -0.02472322 -0.03716445 -0.0418221   0.08248454  0.07601045\n",
      "  -0.10956008  0.11161743  0.04504395  0.0662702   0.11376221 -0.04346874\n",
      "  -0.03588274  0.04869728  0.07684023 -0.10076708 -0.1098843  -0.11070879\n",
      "   0.09173673 -0.02528221 -0.06725121 -0.07040308  0.10951503 -0.04076401\n",
      "  -0.03038013 -0.038059    0.05000575 -0.10894078 -0.03890586  0.08118158\n",
      "   0.03822396 -0.10355529 -0.00622614  0.03152567 -0.11758582  0.11686476\n",
      "   0.00385107 -0.01468026  0.01357412 -0.00731243  0.07659589  0.09988452\n",
      "  -0.0936895   0.03267033 -0.01702622  0.06629068]\n",
      " [-0.05584633  0.02125796  0.0266324  -0.08432022 -0.04103385 -0.03385371\n",
      "  -0.03051104  0.00664658  0.09246364  0.04799811  0.08966079  0.0722949\n",
      "   0.0677004  -0.0047559   0.05880134  0.03841554 -0.07329449  0.11830074\n",
      "   0.05832987 -0.00524965  0.04262057  0.06246945  0.0129727   0.04383038\n",
      "  -0.00724321 -0.01211948 -0.03229164 -0.07628971 -0.00169083  0.10258549\n",
      "   0.06501386 -0.01128404 -0.05525848 -0.02525816 -0.06291452  0.06768373\n",
      "  -0.10181797  0.0573236  -0.07662623 -0.02477723  0.07268313  0.07428716\n",
      "   0.01465305  0.11390845  0.02668742  0.01977614 -0.06087163 -0.07395419\n",
      "  -0.01154174  0.05610565 -0.12313239  0.09260893 -0.05156079 -0.03501441\n",
      "  -0.02841233 -0.09217214  0.07522777 -0.05139949  0.10615949 -0.01683063\n",
      "   0.04031538 -0.04903517  0.05985195 -0.09054554]\n",
      " [-0.0755961   0.00168992  0.07293553  0.06653055 -0.01280956  0.03469002\n",
      "   0.08646854  0.07499029  0.03842692  0.08451574  0.04238733  0.05450408\n",
      "   0.00543294 -0.02054876  0.0193203   0.00337067  0.00344039 -0.12241973\n",
      "   0.10571502  0.01259345  0.10915345  0.10244501  0.04681338 -0.11257111\n",
      "  -0.05850728 -0.05937801 -0.08661836  0.05050886  0.02699828 -0.01919827\n",
      "   0.05925244  0.11476124  0.07560842 -0.10426407 -0.08878525  0.0726862\n",
      "  -0.06855982  0.06796009 -0.09206589  0.07659987  0.09707511  0.08553185\n",
      "   0.02962882  0.07090281 -0.0604403   0.02671563 -0.00370487 -0.11210751\n",
      "   0.06174325  0.05018045 -0.07308513 -0.12109621  0.09986824 -0.08601104\n",
      "  -0.09588245 -0.08157286 -0.05088854  0.07010765  0.028479    0.10646608\n",
      "   0.05099533  0.11733032  0.05535657  0.06774954]\n",
      " [-0.07856935 -0.07154476 -0.09076247  0.0664034  -0.08899058 -0.02518576\n",
      "  -0.05619715 -0.02394199 -0.11430271  0.02553091 -0.09727567  0.02630995\n",
      "   0.07478531 -0.03521042  0.03481475 -0.01950543  0.07859224 -0.05054267\n",
      "   0.02288073 -0.00904734  0.02943638  0.03969131  0.06760843 -0.00772457\n",
      "  -0.08431607 -0.07139523 -0.09006932  0.02101008 -0.00898766  0.1278798\n",
      "  -0.08141385  0.05425784 -0.0647327   0.08510167 -0.08241102  0.07506851\n",
      "   0.02911015  0.12848076 -0.03463791  0.11303659  0.01266275 -0.04490514\n",
      "   0.06423321  0.11988032 -0.02221127  0.04968257  0.04165938  0.02970042\n",
      "  -0.04664089 -0.02797269 -0.04605031 -0.01922187  0.05426679 -0.04173674\n",
      "  -0.02500501  0.02737659  0.0269547   0.05201606  0.08733248 -0.0937354\n",
      "  -0.00123381 -0.04041675  0.10227799  0.00143808]\n",
      " [ 0.10836497 -0.03762199 -0.0779155  -0.10216682  0.03793372 -0.05923699\n",
      "  -0.09206018 -0.02708335 -0.04919563  0.12172779  0.08934242  0.00531003\n",
      "   0.02322425 -0.01693648 -0.02096698 -0.05701694 -0.04467972  0.10024689\n",
      "   0.04707548  0.07608394  0.0404759  -0.1126683   0.07865931 -0.07180423\n",
      "  -0.04226763  0.09588004 -0.11075282  0.0337833  -0.11658895  0.05239035\n",
      "   0.02653271  0.11340704 -0.1026587  -0.07681367  0.07035905 -0.11357281\n",
      "  -0.02213543  0.06838598 -0.02464892 -0.01847214 -0.07535311 -0.09307614\n",
      "  -0.09022929 -0.00991459 -0.079821    0.0197474   0.06216352 -0.03816337\n",
      "  -0.05880784 -0.0858399  -0.00925934  0.12212474  0.01916998 -0.07463602\n",
      "  -0.07890324 -0.05095915 -0.11159068  0.02393004  0.07055217  0.05985301\n",
      "   0.07411892 -0.06406649 -0.04238833 -0.03258572]]\n",
      "q_net.q_net.4.bias: wartości =\n",
      "[ 0.08157522 -0.06757133  0.0100959   0.04044393 -0.08448354]\n",
      "q_net_target.q_net.0.weight: wartości =\n",
      "[[ 2.3925076e-04 -6.5672200e-04  5.3224515e-04 ...  5.3460681e-04\n",
      "   3.4163723e-04 -7.2052394e-04]\n",
      " [ 5.9212238e-04 -4.4889134e-04  7.8002218e-04 ... -3.8859915e-04\n",
      "  -6.8005506e-04 -1.2634526e-04]\n",
      " [ 3.0158254e-04 -7.8318124e-05  4.6163899e-05 ... -5.7490659e-04\n",
      "  -6.3181494e-04 -8.2540227e-04]\n",
      " ...\n",
      " [-7.7338779e-04  3.3001532e-04 -5.0240004e-04 ...  8.0900890e-04\n",
      "   6.5231504e-04  7.0917537e-04]\n",
      " [ 6.9504359e-04 -5.4917444e-04  5.4113590e-04 ...  1.4747500e-04\n",
      "   1.0414750e-04 -6.4103416e-04]\n",
      " [-3.1208736e-04 -3.3204953e-04 -9.6093914e-05 ...  3.7679175e-04\n",
      "   1.5308202e-04  4.0787220e-04]]\n",
      "q_net_target.q_net.0.bias: wartości =\n",
      "[-1.1789298e-03 -6.2681836e-05 -4.2216206e-04 -7.8597368e-04\n",
      "  4.5443727e-03 -7.6337933e-04  5.7958992e-04 -2.5106332e-04\n",
      "  6.7077945e-03 -8.1022724e-04  2.7099820e-03  7.0024695e-04\n",
      " -1.2908038e-03 -4.5241287e-04 -1.5699057e-03 -1.9009312e-04\n",
      " -5.6728095e-05  1.2134899e-04 -3.0146159e-05  4.4372808e-03\n",
      " -8.0119423e-04 -4.0292513e-04 -7.5588777e-04  5.7186042e-03\n",
      " -5.3931883e-04 -3.9345908e-04 -6.9844257e-04 -4.9554277e-04\n",
      " -7.4380462e-04 -1.6364947e-04  5.2252170e-03 -6.9440267e-04\n",
      " -5.0244341e-04 -1.1874967e-03  2.8963624e-03  7.2125072e-04\n",
      "  1.2905311e-03 -4.4551658e-04 -2.3833276e-03  5.4836920e-03\n",
      " -5.4286799e-04 -4.2036193e-04  8.6375076e-04 -6.0028624e-04\n",
      "  6.0584764e-03 -1.0116359e-03  4.8825890e-03  1.1609246e-03\n",
      " -8.0896134e-05 -1.4180418e-03  1.3774490e-03  5.0440216e-03\n",
      " -6.4969639e-04 -5.1396291e-05 -1.1329775e-03  1.2212866e-03\n",
      " -1.0288768e-05 -9.6440915e-04 -1.3163767e-03 -1.4507649e-03\n",
      " -4.5566112e-04 -5.0748611e-04 -7.3393097e-04 -3.9002139e-04]\n",
      "q_net_target.q_net.2.weight: wartości =\n",
      "[[-0.10306998 -0.04740344 -0.04613036 ... -0.12322089 -0.0296732\n",
      "  -0.03088734]\n",
      " [ 0.02961031  0.02182902  0.05546771 ... -0.12281612  0.01522672\n",
      "  -0.12456033]\n",
      " [-0.11510165 -0.10880047 -0.11405376 ...  0.06042151  0.01270445\n",
      "   0.03763252]\n",
      " ...\n",
      " [-0.07725271 -0.09243435 -0.10605598 ... -0.11237203 -0.07401535\n",
      "  -0.0013534 ]\n",
      " [-0.058766   -0.09200688  0.01365319 ...  0.0551217  -0.06085988\n",
      "   0.08738093]\n",
      " [ 0.06602754  0.03505161 -0.06436748 ... -0.08774966  0.07878042\n",
      "  -0.00941203]]\n",
      "q_net_target.q_net.2.bias: wartości =\n",
      "[-0.11907395 -0.09950097  0.00084285 -0.12160436 -0.06967366 -0.01288511\n",
      " -0.05625974 -0.07340997 -0.03108834 -0.1155099   0.05889735  0.12097255\n",
      " -0.11863756 -0.03545842  0.05567651 -0.0656056  -0.08704472 -0.06298754\n",
      "  0.04860168 -0.06693896 -0.06560093  0.01748656 -0.10362199 -0.12838262\n",
      " -0.09395602 -0.11191565  0.00616302  0.01686882 -0.12056156  0.06359376\n",
      " -0.02093779 -0.11916349 -0.10072511 -0.08885793 -0.1262908  -0.10049179\n",
      "  0.10057727 -0.0611189   0.04088519 -0.10811616  0.02131113  0.01597142\n",
      " -0.08551478 -0.04891859  0.03077989 -0.01711522  0.02401372  0.04102203\n",
      " -0.05097034 -0.07463895 -0.04489069  0.10967866 -0.12227336 -0.02364789\n",
      "  0.05883508 -0.08382936 -0.02366786 -0.08930456  0.09144378  0.0918896\n",
      "  0.00692388  0.08050785 -0.11167869  0.00158239]\n",
      "q_net_target.q_net.4.weight: wartości =\n",
      "[[ 0.09309925 -0.04628462 -0.03375402  0.09081764  0.10155195 -0.05083595\n",
      "  -0.04929595  0.04271331  0.05608333  0.12533718  0.02642475  0.08711414\n",
      "  -0.0749092   0.07150223 -0.01468704  0.12011388  0.04359646  0.03170392\n",
      "  -0.05570926 -0.02469181 -0.03716445 -0.0418221   0.08248454  0.07601045\n",
      "  -0.10952812  0.11164653  0.04507524  0.0662702   0.11376221 -0.04346874\n",
      "  -0.03588274  0.04872943  0.07684023 -0.10073581 -0.1098843  -0.11067773\n",
      "   0.09173673 -0.02528221 -0.0672194  -0.07040308  0.10951503 -0.04076401\n",
      "  -0.03038013 -0.038059    0.05000575 -0.10894078 -0.03887015  0.08121423\n",
      "   0.03825516 -0.10352219 -0.00622614  0.03152567 -0.11756167  0.11689641\n",
      "   0.00385107 -0.01464974  0.01357412 -0.00728156  0.07659589  0.09988452\n",
      "  -0.0936895   0.03267033 -0.01702622  0.06629068]\n",
      " [-0.05584633  0.02129003  0.0266324  -0.08432022 -0.04103385 -0.03382195\n",
      "  -0.03051104  0.00664658  0.09246364  0.04799811  0.08966079  0.07232728\n",
      "   0.0677004  -0.0047559   0.05880134  0.03841554 -0.07329449  0.11830074\n",
      "   0.05832987 -0.00521836  0.04262057  0.06246945  0.0129727   0.04383038\n",
      "  -0.00721137 -0.0120907  -0.03226046 -0.07628971 -0.00169083  0.10258549\n",
      "   0.06501386 -0.01125193 -0.05525848 -0.02522703 -0.06291452  0.06771465\n",
      "  -0.10181797  0.0573236  -0.07659455 -0.02477723  0.07268313  0.07428716\n",
      "   0.01465305  0.11390845  0.02668742  0.01977614 -0.06083566 -0.07392158\n",
      "  -0.01151073  0.05613866 -0.12313239  0.09260893 -0.05153701 -0.03498292\n",
      "  -0.02841233 -0.09214172  0.07522777 -0.05136891  0.10615949 -0.01683063\n",
      "   0.04031538 -0.04903517  0.05985195 -0.09054554]\n",
      " [-0.0755961   0.00170711  0.07293553  0.06653055 -0.01280956  0.03470685\n",
      "   0.08646854  0.07499029  0.03842692  0.08451574  0.04238733  0.05452159\n",
      "   0.00543294 -0.02054876  0.0193203   0.00337067  0.00344039 -0.12241973\n",
      "   0.10571502  0.01261003  0.10915345  0.10244501  0.04681338 -0.11257111\n",
      "  -0.05849014 -0.05936318 -0.08660187  0.05050886  0.02699828 -0.01919827\n",
      "   0.05925244  0.1147785   0.07560842 -0.10424756 -0.08878525  0.0727025\n",
      "  -0.06855982  0.06796009 -0.09204903  0.07659987  0.09707511  0.08553185\n",
      "   0.02962882  0.07090281 -0.0604403   0.02671563 -0.00368408 -0.11209008\n",
      "   0.06175965  0.0501984  -0.07308513 -0.12109621  0.09987969 -0.08599421\n",
      "  -0.09588245 -0.08155683 -0.05088854  0.07012371  0.028479    0.10646608\n",
      "   0.05099533  0.11733032  0.05535657  0.06774954]\n",
      " [-0.07856935 -0.07152544 -0.09076247  0.0664034  -0.08899058 -0.02516761\n",
      "  -0.05619715 -0.02394199 -0.11430271  0.02553091 -0.09727567  0.02633054\n",
      "   0.07478531 -0.03521042  0.03481475 -0.01950543  0.07859224 -0.05054267\n",
      "   0.02288073 -0.00902909  0.02943638  0.03969131  0.06760843 -0.00772457\n",
      "  -0.08429696 -0.07137974 -0.09005085  0.02101008 -0.00898766  0.1278798\n",
      "  -0.08141385  0.0542775  -0.0647327   0.08511984 -0.08241102  0.07508629\n",
      "   0.02911015  0.12848076 -0.03461958  0.11303659  0.01266275 -0.04490514\n",
      "   0.06423321  0.11988032 -0.02221127  0.04968257  0.04168673  0.02971927\n",
      "  -0.04662312 -0.02795333 -0.04605031 -0.01922187  0.05428193 -0.04171817\n",
      "  -0.02500501  0.02739563  0.0269547   0.05203229  0.08733248 -0.0937354\n",
      "  -0.00123381 -0.04041675  0.10227799  0.00143808]\n",
      " [ 0.10836497 -0.0376005  -0.0779155  -0.10216682  0.03793372 -0.05921635\n",
      "  -0.09206018 -0.02708335 -0.04919563  0.12172779  0.08934242  0.00533225\n",
      "   0.02322425 -0.01693648 -0.02096698 -0.05701694 -0.04467972  0.10024689\n",
      "   0.04707548  0.07610456  0.0404759  -0.1126683   0.07865931 -0.07180423\n",
      "  -0.04224633  0.09589818 -0.11073206  0.0337833  -0.11658895  0.05239035\n",
      "   0.02653271  0.11342882 -0.1026587  -0.07679313  0.07035905 -0.11355262\n",
      "  -0.02213543  0.06838598 -0.02462818 -0.01847214 -0.07535311 -0.09307614\n",
      "  -0.09022929 -0.00991459 -0.079821    0.0197474   0.06219058 -0.03814209\n",
      "  -0.05878763 -0.08581817 -0.00925934  0.12212474  0.01918686 -0.07461514\n",
      "  -0.07890324 -0.05093804 -0.11159068  0.02394901  0.07055217  0.05985301\n",
      "   0.07411892 -0.06406649 -0.04238833 -0.03258572]]\n",
      "q_net_target.q_net.4.bias: wartości =\n",
      "[ 0.08160663 -0.06754012  0.01011255  0.04046229 -0.0844629 ]\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.save_util import load_from_zip_file\n",
    "\n",
    "# Wczytanie danych bezpośrednio z pliku ZIP\n",
    "data, params, _ = load_from_zip_file(\"pacman_50000_dqn_model.zip\")\n",
    "\n",
    "policy_params = params['policy']\n",
    "\n",
    "# Przeglądanie wszystkich wag\n",
    "for param, value in policy_params.items():\n",
    "    print(f\"{param}: wartości =\\n{value.detach().cpu().numpy()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
