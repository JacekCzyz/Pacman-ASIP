{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "from run import GameController\n",
    "from constants import *\n",
    "from pacman import Pacman\n",
    "from ghost import Ghosts\n",
    "from nodes import NodeGroup\n",
    "from pellets import PelletGroup\n",
    "from fruits import Fruits\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "\n",
    "class PacmanEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "class PacmanEnv(gym.Env):\n",
    "    def __init__(self, render_mode=False):\n",
    "        super(PacmanEnv, self).__init__()\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # Ensure correct SDL driver\n",
    "        if not render_mode:\n",
    "            os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "        else:\n",
    "            os.environ.pop(\"SDL_VIDEODRIVER\", None)\n",
    "\n",
    "        pygame.quit()  # Clean up previous states\n",
    "        pygame.init()\n",
    "\n",
    "        # Pass render_mode to GameController\n",
    "        self.game = GameController(render_mode=render_mode)\n",
    "\n",
    "        # Initialize the observation space\n",
    "        self.action_space = spaces.Discrete(5, start=-2)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255, shape=(SCREENHEIGHT, SCREENWIDTH, 3), dtype=np.uint8\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.startGame(3)  # Rozpoczęcie gry\n",
    "        state = self.get_observation()  # Pobranie stanu początkowego\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = int(action)  # Konwersja akcji na int\n",
    "        action = np.clip(action, 0, 4)  # Upewnij się, że akcja mieści się w zakresie [0, 4]\n",
    "    \n",
    "        # Mappowanie akcji z {0, 1, 2, 3, 4} na {-2, -1, 0, 1, 2}\n",
    "        action = action - 2\n",
    "        if self.game.pacman.validDirection(action):\n",
    "            self.game.pacman.direction = action \n",
    "\n",
    "        pelletBefore = self.game.pellets.numEaten \n",
    "        lifesBefore = self.game.pacman.life_amount   \n",
    "        # Aktualizacja gry\n",
    "        self.game.update()\n",
    "\n",
    "        # Wymuszenie poprawności pozycji Pacmana\n",
    "        if self.game.pacman.target is not None and self.game.pacman.overshotTarget():\n",
    "            self.game.pacman.node = self.game.pacman.target\n",
    "            self.game.pacman.setPosition()\n",
    "\n",
    "        self.game.update()  # Ponowna aktualizacja stanu gry\n",
    "\n",
    "        state = self.get_observation()  # Pobranie nowego stanu po akcji\n",
    "\n",
    "        reward = 0\n",
    "\n",
    "        #pellet = self.game.pacman.eatPellets(self.game.pellets.pelletList)\n",
    "        pellet = self.game.pellets.numEaten - pelletBefore\n",
    "        if pellet == 1:\n",
    "            reward += 20  # Nagroda za zjedzenie pelletu\n",
    "\n",
    "        #liczenie za owocki nie działa drodzy panstwo\n",
    "        fruit = None\n",
    "        if self.game.fruits is not None:  # Sprawdzenie, czy jest owoc\n",
    "            fruit = self.game.pacman.eatFruits(self.game.fruits)\n",
    "            if fruit:\n",
    "                reward += 20  # Nagroda za zjedzenie owocu\n",
    "\n",
    "        # Kara za bycie zjedzonym przez ducha\n",
    "        lifes = self.game.pacman.life_amount - lifesBefore\n",
    "        if lifes == -1:\n",
    "            reward -= 50\n",
    "\n",
    "        # Kara za brak punktów\n",
    "        if pellet == 0 and fruit is None:\n",
    "            reward -= 2\n",
    "\n",
    "        done = self.check_game_over()  # Sprawdzenie, czy gra się skończyła\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return state, reward, done, info\n",
    "    \n",
    "    def render(self, mode=\"human\"):\n",
    "        if self.render_mode and mode == \"human\":\n",
    "            self.game.render()  # Only render if enabled\n",
    "\n",
    "    def get_observation(self):\n",
    "        # Grab the screen as an observation\n",
    "        return pygame.surfarray.array3d(self.game.screen)\n",
    "\n",
    "    def _init_pygame(self):\n",
    "        if not pygame.get_init():\n",
    "            pygame.init()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()  # Zamknięcie pygame\n",
    "\n",
    "    def check_game_over(self):\n",
    "        return self.game.pacman.life_amount == 0  # Gra kończy się, gdy Pacman nie ma żyć\n",
    "    \n",
    "    def change_resolution(self, width, height):\n",
    "        global SCREENWIDTH, SCREENHEIGHT\n",
    "\n",
    "        # Nadpisanie wartości w pliku constants.py\n",
    "        constants_path = os.path.join(os.path.dirname(__file__), \"constants.py\")\n",
    "        with open(constants_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with open(constants_path, \"w\") as file:\n",
    "            for line in lines:\n",
    "                if line.startswith(\"SCREENWIDTH\"):\n",
    "                    file.write(f\"SCREENWIDTH = {width}\\n\")\n",
    "                elif line.startswith(\"SCREENHEIGHT\"):\n",
    "                    file.write(f\"SCREENHEIGHT = {height}\\n\")\n",
    "                else:\n",
    "                    file.write(line)\n",
    "\n",
    "        # Zaktualizowanie zmiennych globalnych w Pythonie\n",
    "        SCREENWIDTH, SCREENHEIGHT = width, height\n",
    "        \n",
    "        # Ponowne załadowanie ustawień (zainicjalizowanie nowego okna gry)\n",
    "        self.game.screen = pygame.display.set_mode((SCREENWIDTH, SCREENHEIGHT))  # Ustawienie nowego rozmiaru okna\n",
    "        self.game.width, self.game.height = SCREENWIDTH, SCREENHEIGHT  # Przekazanie nowych \n",
    "\n",
    "    def get_observation(self):\n",
    "        observation = pygame.surfarray.array3d(self.game.screen)  # Pobranie obrazu z gry\n",
    "        # Zamień wymiary z (width, height, channels) na (height, width, channels)\n",
    "        return np.transpose(observation, (1, 0, 2))  # Zamienia wymiary: (800, 600, 3) na (600, 800, 3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Training the model...\n",
      "Switching to testing mode...\n",
      "Game Over\n",
      "-190\n"
     ]
    }
   ],
   "source": [
    "#Main section to train and test the model\n",
    "env = PacmanEnv(render_mode=False)  # Initialize in training mode\n",
    "model = DQN(\"CnnPolicy\", env, verbose=1, buffer_size=1000)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "model.learn(total_timesteps=2000)\n",
    "model.save(\"pacman_dqn_model\")\n",
    "env.close()  # Properly close the training environment\n",
    "\n",
    "    # TESTING MODE (Rendering enabled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to testing mode...\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "-1978\n"
     ]
    }
   ],
   "source": [
    "print(\"Switching to testing mode...\")\n",
    "env = PacmanEnv(render_mode=True)  # New environment with rendering enabled\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "model = DQN(\"CnnPolicy\", env, verbose=1, buffer_size=1000)\n",
    "\n",
    "model.load(\"pacman_dqn_model.zip\")\n",
    "\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "for _ in range(1000):\n",
    "    # Wybór akcji przez model\n",
    "    action, _states = model.predict(state)\n",
    "        \n",
    "    # Wykonanie akcji w środowisku\n",
    "    state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Renderowanie aktualnego stanu gry\n",
    "    env.render()\n",
    "    rewardMain += reward\n",
    "#         print(rewardMain)\n",
    "\n",
    "    # Jeśli gra się skończyła, wypisanie \"Game Over\" i zakończenie\n",
    "    if done:\n",
    "        print(\"Game Over\")\n",
    "        break\n",
    "    \n",
    "print(rewardMain)\n",
    "    \n",
    "env.close()  # Zamknięcie środowiska\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PacmanEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_vec_env\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the Pacman environment in training mode\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mPacmanEnv\u001b[49m(render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Use training mode (no rendering)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize PPO model with CnnPolicy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCnnPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, ent_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PacmanEnv' is not defined"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Initialize the Pacman environment in training mode\n",
    "env = PacmanEnv(render_mode=False)  # Use training mode (no rendering)\n",
    "    \n",
    "# Initialize PPO model with CnnPolicy\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, n_steps=256, batch_size=64, ent_coef=0.01)\n",
    "\n",
    "print(\"Training the PPO model...\")\n",
    "model.learn(total_timesteps=100)\n",
    "model.save(\"pacman_ppo_model\")  # Save the trained PPO model\n",
    "env.close()  # Properly close the training environment\n",
    "\n",
    "    # TESTING MODE (Rendering enabled)\n",
    "print(\"Switching to testing mode...\")\n",
    "env = PacmanEnv(render_mode=True)  # Create a new environment with rendering enabled\n",
    "    \n",
    "    # Load the trained PPO model\n",
    "model = PPO.load(\"pacman_ppo_model\", env=env)\n",
    "\n",
    "state = env.reset()\n",
    "rewardMain = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trained PPO model:\")\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "for _ in range(1000):\n",
    "    # Predict the next action using the trained PPO model\n",
    "    action, _states = model.predict(state)\n",
    "\n",
    "        # Execute the action in the environment\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Render the current game state\n",
    "    env.render()\n",
    "    rewardMain += reward\n",
    "\n",
    "        # If the game ends, display \"Game Over\" and exit the loop\n",
    "    if done:\n",
    "    print(\"Game Over\")\n",
    "    break\n",
    "\n",
    "print(f\"Total reward during testing: {rewardMain}\")\n",
    "env.close()  # Close the testing environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main section to train and test the model\n",
    "from stable_baselines3 import A2C  # Import A2C zamiast PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Initialize the Pacman environment in training mode\n",
    "env = PacmanEnv(render_mode=False)  # Use training mode (no rendering)\n",
    "    \n",
    "    # Initialize A2C model with CnnPolicy\n",
    "model = A2C(\"CnnPolicy\", env, verbose=1, n_steps=5, ent_coef=0.01, learning_rate=0.0007, gamma=0.99)\n",
    "\n",
    "print(\"Training the A2C model...\")\n",
    "model.learn(total_timesteps=100)  # Train the model\n",
    "model.save(\"pacman_a2c_model\")  # Save the trained A2C model\n",
    "env.close()  # Properly close the training environment\n",
    "\n",
    "    # TESTING MODE (Rendering enabled)\n",
    "print(\"Switching to testing mode...\")\n",
    "env = PacmanEnv(render_mode=True)  # Create a new environment with rendering enabled\n",
    "    \n",
    "    # Load the trained A2C model\n",
    "model = A2C.load(\"pacman_a2c_model\", env=env)\n",
    "\n",
    "state = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trained A2C model:\")\n",
    "state = env.reset()\n",
    "rewardMain = 0\n",
    "for _ in range(1000):\n",
    "        # Predict the next action using the trained A2C model\n",
    "    action, _states = model.predict(state)\n",
    "\n",
    "        # Execute the action in the environment\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Render the current game state\n",
    "    env.render()\n",
    "    rewardMain += reward\n",
    "\n",
    "        # If the game ends, display \"Game Over\" and exit the loop\n",
    "    if done:\n",
    "        print(\"Game Over\")\n",
    "        break\n",
    "\n",
    "print(f\"Total reward during testing: {rewardMain}\")\n",
    "\n",
    "env.close()  # Close the testing environment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
